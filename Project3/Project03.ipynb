{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f128bc6",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Project 3\n",
    "## CS 7324\n",
    "#### Jennifer Carballo & Amory Weinzierl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803cb89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c172408",
   "metadata": {},
   "source": [
    "#### load in datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcded35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in real estate dataset\n",
    "\n",
    "real_estate_df = pd.read_csv(\"data/WakeCountyHousing.csv\")\n",
    "\n",
    "# display df\n",
    "real_estate_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa691381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in reddit upvote dataset - test and train\n",
    "\n",
    "reddit_upvotes_train_df = pd.read_csv(\"data/train_NIR5Yl1.csv\")\n",
    "reddit_upvotes_test_df = pd.read_csv(\"data/test_8i3B3FC.csv\")\n",
    "\n",
    "reddit_upvotes_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c315b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_upvotes_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fff5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in uber fare dataset\n",
    "\n",
    "uber_fares_df = pd.read_csv(\"data/uber.csv\")\n",
    "uber_fares_df = uber_fares_df.rename(columns={'Unnamed: 0': 'index'})\n",
    "uber_fares_df = uber_fares_df.set_index(\"index\")\n",
    "\n",
    "uber_fares_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c561ec05",
   "metadata": {},
   "source": [
    "#### explore data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97990087",
   "metadata": {},
   "source": [
    "##### explore real estate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d8b49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_estate_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27b211a",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_estate_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fe4b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_estate_df.hist(bins=50, figsize=(20,15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b96d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_estate_df.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3911146d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for columnName in real_estate_df:\n",
    "    print(columnName, real_estate_df[columnName].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc00ecd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for columnName in real_estate_df:\n",
    "    print(columnName, real_estate_df[columnName].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e375dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_estate_df['Bath'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72616be",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_estate_df[real_estate_df['Bath'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa15366b",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_estate_df[real_estate_df['Design_Style'] == \"Conventional\"][\"Bath\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80edd033",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_estate_df[real_estate_df['Design_Style'] == \"Condo\"][\"Bath\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0120b645",
   "metadata": {},
   "source": [
    "##### explore reddit upvote training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b12c6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_upvotes_train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328478f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_upvotes_train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1801a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_upvotes_train_df.hist(bins=50, figsize=(20,15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f59c1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_upvotes_train_df.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f1548f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for columnName in reddit_upvotes_train_df:\n",
    "    print(columnName, reddit_upvotes_train_df[columnName].dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9429ad86",
   "metadata": {},
   "source": [
    "##### explore uber fares data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b9e929",
   "metadata": {},
   "outputs": [],
   "source": [
    "uber_fares_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78723317",
   "metadata": {},
   "outputs": [],
   "source": [
    "uber_fares_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1427d42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "uber_fares_df.hist(bins=50, figsize=(20,15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4658f754",
   "metadata": {},
   "outputs": [],
   "source": [
    "uber_fares_df.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9ba678",
   "metadata": {},
   "outputs": [],
   "source": [
    "for columnName in uber_fares_df:\n",
    "    print(columnName, uber_fares_df[columnName].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5195220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# since only two datapoints in entire dataframe are null, simply remove rows where null data is\n",
    "uber_fares_df = uber_fares_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc0d8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "uber_fares_df.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49165bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for columnName in uber_fares_df:\n",
    "    print(columnName, uber_fares_df[columnName].dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f03420",
   "metadata": {},
   "source": [
    "#### executing tasks on real estate df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e98802",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0e84de14",
   "metadata": {},
   "source": [
    "## Executing tasks on reddit train df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30032305-f9bc-49a7-9ece-544251529e67",
   "metadata": {},
   "source": [
    "### Preparing Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b009f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking attribute correlation to upvotes\n",
    "corr_matrix = reddit_upvotes_train_df.corr()\n",
    "corr_matrix[\"Upvotes\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab19eab-fa50-4df4-aad9-a9f0bfdd4e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking combo attributes\n",
    "upvotes_copy = reddit_upvotes_train_df.copy()\n",
    "\n",
    "upvotes_copy[\"rep_per_view\"] = upvotes_copy[\"Reputation\"] / upvotes_copy[\"Views\"]\n",
    "upvotes_copy[\"view_per_rep\"] = upvotes_copy[\"Views\"] / upvotes_copy[\"Reputation\"]\n",
    "upvotes_copy[\"ans_per_view\"] = upvotes_copy[\"Answers\"] / upvotes_copy[\"Views\"]\n",
    "\n",
    "corr_matrix = upvotes_copy.corr()\n",
    "corr_matrix[\"Upvotes\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2391c7e7-6b6a-4801-b8c8-ec313d66f7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# looking at scatter plot for upvotes per views\n",
    "reddit_upvotes_train_df.plot(kind=\"scatter\", x=\"Views\", y=\"Upvotes\", alpha=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf903e78-fdc7-4d1e-b1a8-c707f60453b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove categorical attribute tag from df\n",
    "train_numerical = reddit_upvotes_train_df.copy().drop(\"Tag\", axis=1)\n",
    "test_numerical = reddit_upvotes_test_df.copy().drop(\"Tag\", axis=1)\n",
    "train_numerical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5daa7d-e51e-47ad-bff7-25447e985330",
   "metadata": {},
   "source": [
    "### Scaling Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba124a5-50b7-4c5f-aa02-ad580457d94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "scalar = preprocessing.StandardScaler().fit(train_numerical)\n",
    "X = scalar.transform(train_numerical)\n",
    "prepared_train = pd.DataFrame(X, columns=train_numerical.columns,\n",
    "                          index=train_numerical.index)\n",
    "\n",
    "train_labels = prepared_train[\"Upvotes\"].copy()\n",
    "prepared_train = prepared_train.copy().drop(\"Upvotes\", axis = 1)\n",
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3194301a-232f-47da-95ee-10b0f026ee32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train using forest regression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "forest_reg = RandomForestRegressor(n_estimators=10,\n",
    "                             max_depth=10,\n",
    "                             criterion='squared_error',\n",
    "                            )\n",
    "forest_reg.fit(prepared_train, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52917cf4-d881-4e1f-b74a-8d81a38d5976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying it on training data\n",
    "small_data = prepared_train.iloc[:5]\n",
    "small_labels = train_labels.iloc[:5]\n",
    "print(\"Predictions:\", forest_reg.predict(small_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82d5b0b-31f9-4c98-b95e-700e8ce0fdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Labels:\", list(small_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42985b3c-1142-457e-a445-11196abf1c2f",
   "metadata": {},
   "source": [
    "### Task #1: K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d22a6e5-fba8-448d-bae1-efe64214a3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())\n",
    "\n",
    "x_train = prepared_train[:10000]\n",
    "y_train = train_labels[:10000]\n",
    "    \n",
    "reg_scores = cross_val_score(forest_reg, x_train, y_train, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "reg_rmse_scores = np.sqrt(-reg_scores)\n",
    "\n",
    "display_scores(reg_rmse_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614b90a2-6950-4193-8354-1f8d90b92643",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Task #2: StratifiedK-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc44450-9f0c-4a7e-8e37-87b57c684532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for classifier I will be using the \"tag\" attribute as the target (also I reduced the data set size to 1000 because my laptop is weak)\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.base import clone\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow as tf\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_train_cat = reddit_upvotes_train_df[\"Tag\"][:10000]\n",
    "\n",
    "rnd_clf = RandomForestClassifier()\n",
    "rnd_clf.fit(x_train, y_train_cat)\n",
    "\n",
    "cnt = 1\n",
    "skf = StratifiedKFold(n_splits=3, shuffle=False)\n",
    "for train_index, test_index in skf.split(x_train, y_train_cat):\n",
    "    clone_clf = clone(rnd_clf)\n",
    "    x_train_folds = x_train.iloc[train_index]\n",
    "    y_train_folds = y_train_cat[train_index]\n",
    "    \n",
    "    clone_clf.fit(x_train_folds, y_train_folds)\n",
    "    y_pred = clone_clf.predict(x_train_folds)\n",
    "    print(\"Accuracy for Fold\", cnt, \":\", accuracy_score(y_train_folds, y_pred))\n",
    "    cnt += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27267bdf-6e31-4aa0-b959-d36792c473ba",
   "metadata": {},
   "source": [
    "### Task #3: Use sklearn.mean_squared_error and One Other Option to Evaluate Model Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca1f52b-e0be-4fb0-96c0-be7298468c93",
   "metadata": {},
   "source": [
    "#### Mean Squared Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa7d345-8e2e-4c54-a4e5-c10f7373e1e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "predictions = forest_reg.predict(x_train)\n",
    "reg_mse = mean_squared_error(y_train, predictions)\n",
    "print(\"MSE:\", reg_mse)\n",
    "reg_rmse = np.sqrt(reg_mse)\n",
    "print(\"RMSE:\", reg_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1144ba-d2d7-44df-9e3d-efab75731e63",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### R^2 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6dc681-dcfa-4aa4-8095-f05c822afab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "r2 = r2_score(y_train, predictions)\n",
    "r2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549b5092-c3ef-4201-a71a-e08cf1942b77",
   "metadata": {},
   "source": [
    "### Task #4: Generate a Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d165b773-3153-4af7-9b22-72fc036c09e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "y_pred = cross_val_predict(rnd_clf, x_train, y_train_cat, cv=3)\n",
    "confusion_matrix(y_train_cat, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a0250c-4b31-463d-a225-abafb11922a5",
   "metadata": {},
   "source": [
    "### Task #5: Generate ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6fa0a4-65a6-4423-ab14-49a8e819adef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regression for multi-class classification using a one-vs-rest (must convert into binary classification to do this task)\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "model = LogisticRegression()\n",
    "ovr = OneVsRestClassifier(model)\n",
    "ovr.fit(x_train, y_train_cat)\n",
    "yhat = ovr.predict(x_train)\n",
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34595a6e-eff1-4067-8733-3319c97433b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "y_scores = cross_val_predict(ovr, x_train, yhat, cv=3,\n",
    "                             method=\"decision_function\")\n",
    "fpr, tpr, thresholds = roc_curve(yhat, y_scores, pos_label={'a', 'c', 'r', 'j', 'p', 's', 'h', 'o', 'i', 'x'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9985041e-9479-4a90-8770-d750428edd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(fpr, tpr, label=None):\n",
    "    plt.plot(fpr, tpr, linewidth=2, label=label)\n",
    "    plt.plot([0, 1], [0, 1], 'k--') # Dashed diagonal\n",
    "    \n",
    "plot_roc_curve(fpr, tpr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba3eaf7-15b3-4ce6-b3ec-718a433b367d",
   "metadata": {},
   "source": [
    "### Task #6: Use Grid Search CV to Tune Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf43ddc-294d-4165-b42e-8a231dbfb9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [\n",
    "    {'n_estimators': [3, 10, 30], 'max_features': [2, 4, 6, 8]},\n",
    "    {'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [2, 3, 4]},\n",
    "  ]\n",
    "\n",
    "new_forest_reg = RandomForestRegressor()\n",
    "grid_search = GridSearchCV(new_forest_reg, param_grid, cv=5,\n",
    "                           scoring='neg_mean_squared_error',\n",
    "                           return_train_score=True)\n",
    "\n",
    "grid_search.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6afc7b8-b623-43b5-8ed8-3ec88c81a98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cvres = grid_search.cv_results_\n",
    "\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(np.sqrt(-mean_score), params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f62a9f-3310-48ee-ad0a-f71010f7a08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32020fde-3cc0-4082-9bad-6fb02b83bfa3",
   "metadata": {},
   "source": [
    "### Task #7: Use an Ensemble of Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36f0501-624c-490e-aa94-76c1b3e472c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "small_x = x_train[:1000]\n",
    "small_y = y_train_cat[:1000]\n",
    "\n",
    "log_clf = LogisticRegression()\n",
    "rnd_clf = RandomForestClassifier()\n",
    "svm_clf = SVC()\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('lr', log_clf), ('rf', rnd_clf), ('sv', svm_clf)],\n",
    "    voting='hard')\n",
    "voting_clf.fit(small_x, small_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7e8705-4078-486f-8d91-df44b124feba",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = voting_clf.predict(small_x)\n",
    "print(\"Ensemble Accuracy: \", accuracy_score(small_y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce97b11-46c4-4db8-a2ec-5177e01e28d2",
   "metadata": {},
   "source": [
    "### Task #8: Evaluate Your System on the Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fda8444-beb3-4f8d-8976-7b67c75eed03",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = grid_search.best_estimator_\n",
    "\n",
    "x_test = prepared_train[1000:2000]\n",
    "y_test = train_labels[1000:2000]\n",
    "\n",
    "final_model.fit(x_test, y_test)\n",
    "final_predictions = final_model.predict(x_test)\n",
    "\n",
    "final_mse = mean_squared_error(y_test, final_predictions)\n",
    "final_rmse = np.sqrt(final_mse)\n",
    "final_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d59fe56-c81b-4004-9680-a07feb01424e",
   "metadata": {},
   "source": [
    "### Task #9: Create a Single Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd58e16-2da4-4d83-9e90-fc1e68d558eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "numeric_features = ['ID', 'Reputation', 'Answers', 'Username', 'Views']\n",
    "categorical_features = ['Tag']\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "       ('imputer', SimpleImputer(strategy='mean'))\n",
    "      ,('scaler', StandardScaler())\n",
    "])\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "       ('imputer', SimpleImputer(strategy='constant'))\n",
    "      ,('encoder', OrdinalEncoder())\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "   transformers=[\n",
    "    ('numeric', numeric_transformer, numeric_features)\n",
    "   ,('categorical', categorical_transformer, categorical_features)\n",
    "]) \n",
    "\n",
    "pipeline = Pipeline(steps = [\n",
    "               ('preprocessor', preprocessor)\n",
    "              ,('regressor', RandomForestRegressor(bootstrap=False, max_features=4, n_estimators=10)),\n",
    "           ])\n",
    "\n",
    "y_upvotes = reddit_upvotes_train_df[\"Upvotes\"]\n",
    "x_upvotes = reddit_upvotes_train_df.copy().drop(\"Upvotes\", axis=1)\n",
    "x_test = x_upvotes[1000:2000]\n",
    "y_test = y_upvotes[1000:2000]\n",
    "\n",
    "model = pipeline.fit(x_upvotes, y_upvotes)\n",
    "final_predictions = model.predict(x_test)\n",
    "final_mse = mean_squared_error(y_test, final_predictions)\n",
    "final_rmse = np.sqrt(final_mse)\n",
    "final_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa885cc",
   "metadata": {},
   "source": [
    "#### executing tasks on uber fares df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1991bd82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
